[{"title":"Why do deep convolutional networks generalize so poorly to small image transformation?","date":"2020-04-28T14:20:48.000Z","path":"2020/04/28/2019 Why do deep convolutional networks generalize so poorly to small image transformation/","text":"Why do deep convolutional networks generalize so poorly to small image transformation?Abstract CNN通常被认为是对较小的图像变换具有不变性的。 或因为卷积的架构 或因为训练时进行了数据增强 近期，不少作者发现实际情况并不是这样。 较小的图像变换或缩放导致网络的预测结果变换极大。 本文对该现象进行了量化，分析了数据增强和卷积结构不足以带来不变性的原因。 作者观点： 由于卷积架构忽视了传统的采样定理。 数据增强仅能让CNN对类似训练集中的变换具有不变性。 提出两个解决方法： 对中间特征表示进行抗锯齿处理 进一步进行数据增强 提出的解决方法仅解决了部分问题，因此如何使得模型具备轻微变换不变性仍然未被解决。 Introduction 深层卷积网络的成功已经彻底改变了计算机视觉领域 尤其在目标识别领域中，达到了super-human CNN中的归纳偏置 CNN中卷积和池化操作的设计思路就是为了使网络对变换、缩放、变形等不敏感 数据增强 crop：随机位置、随机大小，因此图像会以不同偏移形式或大小进行训练。 从而让模型学到与平移缩放无关的判别特征。 实际上CNN十分脆弱，细微变化都带来巨大的预测变化，图1 一个像素的平移 一个像素的缩放 难以察觉的姿势变换 本文解释归纳偏置失败的原因 首先对该现象系统地进行量化 并展示该现象出现在不同结构的CNN中，同时与缩放和变换算法无关，向下平移一个像素可能导致分类概率变化多达30%。 分别介绍两个归纳偏置失败的原因 CNN忽略传统采样定理，因此锯齿效应导致不变性缺失 数据增强使网络学到类似训练数据集中的变换模式，由于数据集中的分布本身就有bias，故导致与训练数据分布不同的图像缺失不变性。 Quantifying the lack of invariance in modern CNNs 使用六种不同CNN，为每种CNN以4种方式展示了1000张图片 基础实验： 从ImageNet测试集中随机选取一张图片，用四种方式对图片进行一个像素的扰动，测量网络的敏感程度。 敏感程度的测量使用两种方法： P(Top-1 change)： Top-1预测的变化概率。 mean absolute change： Top-1概率的平均变化值 二者捕捉不同的稳定性特征： P(Top-1 change) 对最后一层输出的单调变换具有不变性 mean absolute change 用于排除相近类别带来的top1预测变化 四种方式： 在图像中随机截取一个框再resize到224x224。再进行一个像素的对角线平移 embedding: 保持长宽比降采样到短边尺寸为100，再随机嵌入到224x224图像中的随机位置，空余用黑色像素填充。再进行一个像素平移 类似第二种方法，但是用图像修复算法补全空余部分。 类似第二种方法，增大被嵌入图像一个像素单位。 优劣势： 第一种方法可能导致重要信息丢失，平移后边缘信息会有区别。 第二种方法虽然保留了所有信息，但是可能引入非典型边界像素。 带来的细微变化都是人类无法感知到的、可辨识度没有变化 景观变化是人类难以感知的，但模型预测类别变化的概率可以达到30%，故此前论文中关于CNN缺乏不变性的报告不是偶然而有着很高的出现频率。 对于此结果的质疑可以是这些变换的图像在训练集中没有见过。引出两个对不变性的定义 完全不变性：对任何模式以及其变换的形式输出相同的结果 部分不变性：在某种模式或与其类似的模式在训练集中出现的前提下，输出相同的结果。 实验结果指明CNN并不是完全不变性。 Ignoring the Sampling Theorem 直觉上，如果网络所有层都是卷积的，那么特征表示应该随着图像变换而变换。 这种直觉忽视了CNN中的下采样。1992年文献”Shiftable multiscale transforms.”中提到：我们不能指望基于卷积和下采样的系统拥有变换不变性，除非变换的幅度为下采样的整数倍 “We cannot literally expecttranslation invariance in a system based on convolution and subsampling: translation ofthe input signal cannot produce simple translations of the transform coefficients, unless thetranslation is a multiple of each of the subsampling factors in the system”. 由于CNN包含很多下采样操作，因此网络深层的下采样系数会变得很大，因此变换不变性仅对某些特定的变换成立。文献“Making convolutional networks shift-invariant again.”正式了CNN确实能在平移恰好为下采样因子的整数倍时成立。 Simoncelli还定义了变换不变性的一种较弱的形式“Shiftability”，并展示了它在存在下采样的系统中仍然成立，在此基础上，本文展示当“Shiftability”成立时，使用全局平均池化能够获得不变的特征表示。 定义$r(x)$为特征提取器在位置$x$的response，$r(x)$是convolutional当且仅当平移输入图像$δ$个像素，得到的response也平移$δ$个像素。 如果$r(x)$是convolutional的，全局池化$r=\\sum_{x} r(x)$是平移不变的，不论该模式是否在训练集中出现。（卷积步长为1时）","tags":[{"name":"CV","slug":"CV","permalink":"http://lossherl.github.io/tags/CV/"}]},{"title":"Unpaired Photo-to-manga Translation Based on The Methodology of Manga Drawing","date":"2020-04-27T04:29:48.000Z","path":"2020/04/27/2020 Unpaired Photo-to-manga Translation Based on The/","text":"Unpaired Photo-to-manga Translation Based on The Methodology of Manga DrawingAbstract 首个彩色照片转黑白漫画的方法。 细致地将每个面部区域转化成漫画风格。 收集数据集，包含面部特征，特征点，身体等 提出结构化平滑loss，用于平滑线条避免噪声像素。 提出照片和漫画的相似度量 Introduction 漫画生成的挑战 相比现实照片，漫画中的人脸是抽象的、表情是夸张的。 不同漫画家有不同的风格，外貌、位置、大小和风格这些要素很难仅用一个网络同时抽取。 维持个体特征的同时融入漫画风格 数据难获取 画家绘制漫画的过程 画出大致面部轮廓 分布面部特征 精细的绘制每个部分 MangaGAN遵循这个过程，使用多个GAN转换不同的部位特征，再用另外的GAN完成映射。 利用相似度模块维持个体身份，并通过结构平滑loss避免噪声。 主要贡献： 仿照绘制漫画的过程，使用多个部位GAN将照片转化为漫画 提出相似度维持模块保证面部特征不变、提出平滑loss防止噪声。 构造数据集 Method MangaGAN有两个分支 Geometric Transformation Network （GTN）学习面部的几何映射。 Appearance Transformation Network （ATN）学习外貌映射。 最后由生成模块聚合各个组件，输出漫画头像。 ATN 包含四个局部GAN，分别对应眼睛、鼻子、嘴巴、头发。 眼睛和嘴 眼睛和嘴是漫画中的最重要的部分，也是最难转换的 使用类似CycleGAN的方法来回映射 生成器使用Resnet 6 blocks，辨别器使用马尔科夫70x70的patchGANs。 均方误差loss代替极大似然作为对抗损失（更稳定） Cycle Loss采用一阶范数差 上述两种Loss在实验中仍让不足以保证相似度。 提出Similarity Preserving (SP) module 主要思想是维持低分辨率时的相似度能够在上采样后给出尅死的空间分布和不同的像素细节。 使用一个预训练的卷积网络抽取不同尺寸的图像特征 最小化不同之尺寸下生成部件图像与真实部件图像的特征二阶范数和像素二阶范数 训练编码器$E_{eye}$得到眼睛的01特征，对嘴巴同理，将其转化为二进制的线条。 结构化平滑Loss 基于高斯模型。 主要思想是给予灰度值接近黑和白的像素更低 loss，从而让结果更清晰。 头发和鼻子 漫画脸中鼻子并不重要，因为大多数漫画人物的鼻子都很相似，因此鼻子的部分采用的是生成的方法，而不是转换的方法。 采用类似ProGAN的方式，训练变分自编码器将鼻子编码为特征向量，再作为种子生成默认的漫画鼻子。 允许用户对其进行修改。 头发的部分采用预训练的APDdrawingGAN，能够生成风格类似漫画的黑白头发。 首先使用头发分割模型抽取粗略的头发区域，再去除背景区域。 GTN 目标 面部的几何特征（106个面部特征点）的风格迁移 将几何属性分为脸型、面部特征位置、大小，对应三个子GAN 为增强多样性，使用相对位置而不是直接生成特征点坐标 位置： 特征点坐标被表示成｛左眼、右眼、鼻子、嘴｝四个部分，每个部分用若干个相对位置标量表示，例如鼻子由到左侧脸颊的距离、到右侧脸颊的距离、到底部的距离表示。 大小： 眼睛、鼻子、嘴巴的宽度 脸型： 17个脸颊轮廓特征点 训练同样采用Cycle Loss + Adversial Loss，额外加入角色Loss，通过比较一张脸与平均脸的差异（特征点的余弦相似度） 生成组件 首先缩放各面部部件并根据几何特征放置 脸型部分用曲线链接生成的特征点（Piecewise Cubic Hermite Interpolating Polynomial (PCHIP)），该方法能够得到平滑曲线，维持面部形状 对于耳朵区域，使用十个备选。","tags":[{"name":"CV","slug":"CV","permalink":"http://lossherl.github.io/tags/CV/"}]},{"title":"Attention Is All You Need","date":"2020-04-07T14:16:48.000Z","path":"2020/04/07/2017 Attention Is All You Need/","text":"Attention Is All You NeedAbstract 序列转换模型通常基于复杂的RNN或CNN，包含一个编码器和一个解码器。最表现最好的模型还在编解码器之间使用注意力机制链接。 他提出一个简单的网络结构Transformer，仅基于注意力机制。 Introduction 序列化计算瓶颈： 循环神经网络将序列位置对齐到计算时的时间步，继承了序列的自然形式但使得并行计算无法进行。 注意力机制在许多任务模型中变得不可或缺，它使得不论二者在序列中距离远近都可以对其依赖关系进行建模。 Model Architecture 大多数序列转换模型都采用编解码器结构，编码器将输入编号序列$x$转化为表示序列$z$，给定$z$，解码器生成输出序列$y$，生成时每一步的输入为上一时刻输出的编号。 Transformer遵循类似的框架，编码器与解码器均是堆叠自注意力层、点乘和全连接层。 编码器包含N=6个相同层，每层有两个子层，均采用参差连接紧接着一个Layer Normalization。 多头自注意力层。 position-wise全连接前馈层。 解码器也包含N=6个相同层，在编码器两个子层的基础上添加了第三个子层，在编码器的输出上进行多头注意力机制。同时在自注意力层加上了mask，使得预测时仅能依赖前序已知的输出。 注意力可被看作是query与一系列key-val对匹配，得到输出。输出是val的加权和，每个val的权值通过query和对应key的相关程度计算得到。 Scaled Dot-Product Attetnion $Attention (Q, K, V)=\\operatorname{softmax}\\left(\\frac{Q K^{T}}{\\sqrt{d_{k}}}\\right) V$ Q,K的维度为 $d_k$，V的维度为$d_v$ 注意力两种常见形式：Additive Attention和dot-product。后者计算更亏且空间更高效（由于高效的矩阵乘法），Additive Attention是通过有一个隐层的前馈网络计算相似度的。二者在$d_k$较小时表现相当，但若$d_k$变大且没有scale（保证方差为1，维持标准正态分布）项时，前者表现更好。 Multi-Head Attention 实验发现使用多个不同线性层分别映射QKV到各自子空间带来了好的效果。在各自子空间计算输出后再连接并经过线性映射得到最终输出。 $\\operatorname{MultiHead}(Q, K, V) { Concat(head }{1}, \\ldots, \\text { head }{\\mathbf{h}}) W^{O}$ $head {\\mathbf{i}}Attention(Q W{i}^{Q}, K W_{i}^{K}, V W_{i}^{V})$ $W_{i}^{Q} \\in \\mathbb{R}^{d_{\\text {model }} \\times d_{k}}, W_{i}^{K} \\in \\mathbb{R}^{d_{\\text {model }} \\times d_{k}}, W_{i}^{V} \\in \\mathbb{R}^{d_{\\text {model }} \\times d_{v}}$ and $W^{O} \\in \\mathbb{R}^{h d_{u} \\times d_{\\text {matel }}}$ 文章中h=8，$d_k=d_v=d_{model}/h=64$，随着维度降低，总体计算复杂度与单头类似、 Transformer中使用了三种形式的注意力 Encoder-Decoder Attention：Query来自前一层的解码器，key和value来自编码器的输出，使得解码器的每个位置都可以注意到输入序列的每个位置。类似传统编解码器结构。 编码器自注意力：qkv均为上一层的编码器输出，编码器的每个位置都可以关注到上一层编码器输出的所有位置。 解码器自注意力：类似编码器中的自注意力，但是使用mask阻断由后往前不合法的连接。 另外一个子层为Position-wise前馈层。包含两个线性层以及一个ReLU。 使用embedding得到每个输入token的$d_{model}$向量形式，同时使用线性层和softmax将解码器输出转换为下一个单词的预测概率。 Positional Encoding 由于没有循环和卷积操作，为了让模型感知输入序列的顺序，必须置入token之间的相关位置或绝对位置信息。 Positional Encoding和输入有着相同的维度，直接加和。 使用不同频率的正余弦函数构造出各位置的独立编码。 使正余弦函数的原因：作者假设模型能够简单地学到如何attend by relative positions，由于对于任何offset k，在正余弦函数中， $PE_{pos+k}$都能通过$PE_{pos}$的线性变换表示。 由于后续注意力前都使用线性层映射特征到低维形式，输入特征都被重组，因此相加和拼接差别应该不大，直接累加起到的作用可能是神经网络在训练中识别得出的。 Why Self-Attention 单层计算复杂度 可并行计算的计算量 最长距离依赖的计算路径长度（对学习长期依赖十分关键），距离越短越容易学习关系（在网络中传输的次数越少） 可解释性","tags":[{"name":"NLP","slug":"NLP","permalink":"http://lossherl.github.io/tags/NLP/"}]},{"title":"Non-local Neural Networks","date":"2020-03-29T11:20:48.000Z","path":"2020/03/29/2018 Non-local Neural Networks/","text":"Non-local Neural NetworksAbstract 卷积和递归操作都是每次处理局部周边的信息。 本文受Non-local means启发，提出一种Non-local Block用于长距离依赖，在Non-local中，每个位置的反馈为所有位置特征的加权求和，该block能够插入任意的神经网络中。 Introduction 捕捉长距离依赖的重要性 CNN：通过增大感受野 RNN：序列递归 上述两种操作分别在时间和空间上是局部的，因此长距离依赖仅能通过不断重复操作达到。 重复操作有着许多局限性 计算不高效 优化困难 多跳依赖困难（信息在距离较远的位置间来回传播） 本文提出的Non-local操作是Non-local means的一般化版本。其中，每个位置的反馈为所有位置特征的加权求和，这些位置可以是时间、空间或是时空（视频的不同帧）上的。 Non-local的优势 与CNN、RNN逐步递进的方式不同，Non-local直接计算各位置间的交互获取长距离依赖，无视二者间的距离。 运算高效，仅需要很少的层数就能达到好的效果。 维持了输入特征的尺寸，因此容易和其他操作结合。 在视频分类中，长距离依赖发生在时间上和空间上，单个Non-local block都能直接捕捉这些依赖，通过堆叠多个non-local block，本文提出的模型在视频任务中超过了2D和3D的CNN模型，且相比3D CNN，Non-local计算上更经济。 实验中通过目标检测和姿势预测等任务证实了该模块在视觉任务上的效果，仅增加了些许额外计算代价便带来了精度提升。 Related Work Non-local image processing 非局部均值 BM3D （图像去噪算法） Non-local匹配也在纹理生成、超分辨率以及图像修复等领域中有着重要作用。 图模型 长距离依赖也可以用图建模，例如条件随机场 （CRF）。 在神经网络中，条件随机场可以用于后处理语义分割的结果。 本文的Non-local是更简单的前馈操作。 序列的前馈建模 这类方法中，长距离依赖通过大感受野的一维卷积得到。且能够并行实现。 自注意力 本文提出的方法类似于机器翻译中的自注意力。 机器翻译中的注意力是计算每个位置与其他位置的对其关系，得到加权平均值。 自注意力可看作是非局部均值的一钟形式。 交互网络 视频分类框架 沿用CNN并用RNN处理序列。 光流和轨迹是有效的，包含了长距离非局部的依赖。 Non-local Neural Networks公式$$\\mathbf{y}{i}=\\frac{1}{\\mathcal{C}(\\mathbf{x})} \\sum{\\forall j} f\\left(\\mathbf{x}{i}, \\mathbf{x}{j}\\right) g\\left(\\mathbf{x}_{j}\\right)$$ 其中，i为输出位置坐标，f为相似度计算函数，g计算每个输入信号的特征表示。 由于所有位置都被考虑在内，故该操作为非局部操作。 Non-local与全连接层也存在不同，Non-local的依据是位置间的相似关系，而fc仅使用学习到的参数。同时Non-local不限制输入的大小，且输出维持输入的尺寸。 Non-local block是可扩展的，能够与卷积层或递归层一同使用。 实例化 Non-local对f和g函数的选取不敏感。 简单起见，g使用线性映射：$g\\left(\\mathbf{x}{j}\\right)=W{g} \\mathbf{x}_{j}$ 类似Non-local means和双边滤波，f选用高斯函数：$f\\left(\\mathbf{x}{i}, \\mathbf{x}{j}\\right)=e^{\\mathbf{x}{i}^{T} \\mathbf{x}{j}}$。可简单扩展为：$f\\left(\\mathbf{x}{i}, \\mathbf{x}{j}\\right)=e^{\\theta\\left(\\mathbf{x}{i}\\right)^{T} \\phi\\left(\\mathbf{x}{j}\\right)}$，其中，$\\theta\\left(\\mathbf{x}{i}\\right)=W{\\theta} \\mathbf{x}{i}$与$\\phi\\left(\\mathbf{x}{j}\\right)=W_{\\phi} \\mathbf{x}{j}$为两个嵌入。规格化函数：$\\mathcal{C}(\\mathbf{x})=\\sum{\\forall j} f\\left(\\mathbf{x}{i}, \\mathbf{x}{j}\\right)$ 机器翻译的自注意力可形式化为：$\\mathbf{y}=\\operatorname{softmax}\\left(\\mathbf{x}^{T} W_{\\theta}^{T} W_{\\phi} \\mathbf{x}\\right) g(\\mathbf{x})$，本文将序列化的自注意力延伸到更一般的时空结构中。 f还可以定义为点积：$f\\left(\\mathbf{x}{i}, \\mathbf{x}{j}\\right)=\\theta\\left(\\mathbf{x}{i}\\right)^{T} \\phi\\left(\\mathbf{x}{j}\\right)$，同时规格化因子变为：$\\mathcal{C}(\\mathbf{x})=N$，N为x中位置的数量。点积版本与高斯版本的区别在于是否使用softmax。 连接版本：$f\\left(\\mathbf{x}{i}, \\mathbf{x}{j}\\right)=\\operatorname{ReLU}\\left(\\mathbf{w}{f}^{T}\\left[\\theta\\left(\\mathbf{x}{i}\\right), \\phi\\left(\\mathbf{x}_{j}\\right)\\right]\\right)$，规格化因子与点积版本相同。 Non-local Block 可定义为：$\\mathbf{z}{i}=W{z} \\mathbf{y}{i}+\\mathbf{x}{i}$，$+\\mathbf{x}{i}$为残差连接，加入残差连接并将$W{z}$初始化为零使得Non-local block可以插入任何预训练模型中，且不影响初始形态的动作。 在计算上，pair间的计算可通过矩阵相乘完成，类似卷积层的计算量。 实现上，$W_{g}, W_{\\theta},$ 和 $W_{\\phi}$的输出通道数减为x的一半，服从bottleneck的设计法则并减少了一半的计算量，最后的$W_{z}$将维度转换回x的维度。 还可以通过下采样进一步降低计算量，在$\\phi$ 和 $g$之后添加最大池化层。 视频分类模型 2D卷积模型：时间维度上使用池化聚合各个帧的信息 3D卷积模型：卷积核为t x k x k，覆盖t帧 Non-local Network：在2D卷积和3D卷积模型中插入Non-local block","tags":[{"name":"CV","slug":"CV","permalink":"http://lossherl.github.io/tags/CV/"}]},{"title":"Squeeze-and-Excitation Networks","date":"2020-03-29T10:20:48.000Z","path":"2020/03/29/2017 Squeeze-and-Excitation Networks/","text":"Squeeze-and-Excitation NetworksAbstract 卷积操作是通过聚合局部空间上和各通道上的信息从而增强特征表示 本文提出的Squeeze-and-Excitation（SE） Block通过建模通道间的相互依赖关系，重新刻画通道维度上的特征。 Introduction 本文提出的机制能够使网络能够利用全局信息来强调重要的特征同时压制不重要的部分。 SE Block结构如下图：输入X由卷积操作得到特征矩阵U，特征U首先通过Squeeze操作，即在空间维度上聚合特征，目的是获得各个通道的全局分布特征。 Excitation操作紧跟Squeeze操作，通过一个简单的self-gate机制，为输入的每个通道输出权重。这些权重随后应用在特征矩阵U上。 SE块在网络的不同深度起到不同的作用。 在网络浅层，与类别无关，增强低层面公共的特征。 在网络深层，越来越细化，给出与类别更为相关的反馈。 因此，SE Block得到的特征增强会随着层数加深不断累积。 结构简单，可直接替换成熟网络中的block。 Related Work 此前跨通道的操作一般为1x1卷积，大多集中于降低模型计算复杂度。本文认为在通道间使用全局信息施加动态非线性依赖能够加快学习过程，并提升网络的特征表示能力。 Squeeze-and-Excitation Blocks公式输入：$\\mathbf{X} \\in \\mathbb{R}^{H^{\\prime} \\times W^{\\prime} \\times C^{\\prime}}$ 输出：$\\mathbf{U} \\in \\mathbb{R}^{H \\times W \\times C}$，$\\mathbf{U}=\\left[\\mathbf{u}{1}, \\mathbf{u}{2}, \\ldots, \\mathbf{u}{C}\\right]$，$\\mathbf{u}{c} \\in \\mathbb{R}^{H \\times W}$ 卷积核：$$\\mathbf{V}=\\left[\\mathbf{v}{1}, \\mathbf{v}{2}, \\dots, \\mathbf{v}_{C}\\right]$$， $$\\mathbf{u}{c}=\\mathbf{v}{c} \\mathbf{X}=\\sum_{s=1}^{C^{\\prime}} \\mathbf{v}_{c}^{s} \\mathbf{x}^{s}$$ 实质上，卷积输出是各个通道间结果的加和，因此，通道间的依赖关系也隐含在了卷积核$\\mathbf{V}_{c}$中，但是与卷积核捕捉到局部关联性纠缠在了一起。 因此SE-block用全局信息以显式地建模通道间的关系。 Squeeze 卷积操作仅在局部感受野上操作，因此输出的每个单元都无法利区域周边的信息。 为减轻上述问题，Squeeze操作将空间上的全局信息作为通道描述信息（Global Avgpooling），$z_{c}=\\mathbf{F}{s q}\\left(\\mathbf{u}{c}\\right)=\\frac{1}{H \\times W} \\sum_{i=1}^{n} \\sum_{j=1}^{w} u_{c}(i, j)$ Excitation：Adaptive Recalibration 利用Squeeze得到的全局信息，捕捉通道间的依赖关系。 两点要求： 此操作能够学习通道间的非线性交互关系 学习的是不互斥的关系，我们需要多个通道可以被同时高亮。 简单地用sigmoid激活：$\\mathbf{s}=\\mathbf{F}{e x}(\\mathbf{z}, \\mathbf{W})=\\sigma(g(\\mathbf{z}, \\mathbf{W}))=\\sigma\\left(\\mathbf{W}{2} \\delta\\left(\\mathbf{W}{1 \\mathbf{Z}}\\right)\\right)$，其中，$\\mathbf{W}{1} \\in \\mathbb{R}^{\\frac{c}{r} \\times C}$， $\\mathbf{W}_{2} \\in \\mathbb{R}^{C \\times \\frac{c}{r}}$，δ为ReLU。即两个FC层之间插入非线性层。 $\\widetilde{\\mathbf{x}}{c}=\\mathbf{F}{\\text {scale }}\\left(\\mathbf{u}{c}, s{c}\\right)=s_{c} \\mathbf{u}{c}$，$\\mathbf{F}{\\text {scale }}\\left(\\mathbf{u}{c}, s{c}\\right)$为通道维度乘法。 Excitation操作将输入的通道描述映射为一系列的通道权重。可视为通道上的自注意力机制，但不局限于感受野的大小。 模型与计算复杂度 相比ResNet，SE-ResNet增加了0.26%的浮点运算次数（3.87GFLOPs），得到的精度接近ResNet-101（7.58GFLOPs）。 增加的参数数量为两个fc的参数。 实验 SE在各个深度网络中得到的收益是一致的，表明SE block得到的收益可以与深度提升的收益互补。 r的选取是鲁邦的， 提高复杂度并不能不断提高准确度，r=16是平衡的取值。 Squeeze操作中，平均池化与最大池化效果相当，平均池化略好。 Excitation中，非线性函数改用ReLU的效果最差，tanh居中，Sigmoid最好，非线性函数的选取较为重要。 在不同阶段添加SE Block精度均有提升，且不同阶段的提升是互补的，在所有阶段均添加能得到最大的提升。 比较SE添加的位置（残差前、残差后等），发现SE对添加的位置也具有鲁棒性。 若将全局池化替换为1x1卷积，失去了全剧信息，精度略有下降，但仍高于原本的ResNet。","tags":[{"name":"CV","slug":"CV","permalink":"http://lossherl.github.io/tags/CV/"}]},{"title":"Non-local Networks Meet Squeeze-Excitation Networks and Beyond","date":"2020-03-19T13:08:48.000Z","path":"2020/03/19/2019 GCNet Non-local Networks Meet Squeeze-Excitation Networks and Beyond/","text":"GCNet: Non-local Networks Meet Squeeze-Excitation Networks and BeyondAbstract 发现在NL中，不同位置的query得到的反馈几乎是一样的 本文提出基于query-independent formulation的简单网络，在保持NLNet精确度的同时大大减少了计算量。 由于本文结构与SENet有着蕾丝的结构，因此本文将二者结合得到一个三步的全局上下文建模方法。 Introduction 在NL中，对于每个位置query，模块输出该位置与所有位置的两两关系，产生注意力矩阵，再将各位置的特征加权求和累加在query位置上。 但是在可视化分析中发现，不同位置query得到的注意力矩阵几乎是一样的，这表明学习到的只是与query无关的依赖关系。 基于上述观察，本文简化了NL块，对所有位置使用一致的注意力矩阵，减少了大量的计算，同时没有精度损失。 SENet与简化后的NL类似，区别在于聚合、变换、加强特征等方法的选用。将这些方法抽象化，得到一个三步框架。 context modeling module：聚合所有位置的特征得到全局特征。 feature transform module：捕捉通道间的依赖关系。 fusion module：合并全局信息与各位置的信息。 Analysis on Non-local Networks NL公式：$\\mathbf{z}{i}=\\mathbf{x}{i}+W_{z} \\sum_{j=1}^{N_{p}} \\frac{f\\left(\\mathbf{x}{i}, \\mathbf{x}{j}\\right)}{\\mathcal{C}(\\mathbf{x})}\\left(W_{v} \\cdot \\mathbf{x}{j}\\right)$，$\\omega{i j}=\\frac{f\\left(\\mathbf{x}{i}, \\mathbf{x}{j}\\right)}{\\mathcal{C}(\\mathbf{x})}$，Embedded Gaussian版本：$\\omega_{i j}=\\frac{\\exp \\left(\\left\\langle W_{q} \\mathbf{x}{i}, W{k} \\mathbf{x}{j}\\right\\rangle\\right)}{\\sum{m} \\exp \\left(\\left\\langle W_{q} \\mathbf{x}{i}, W{k} \\mathbf{x}{m}\\right\\rangle\\right)}$。最后一个卷积$W{z}$加不加没有多大影响。 NL可看作全局信息建模单元，将所有位置的信息加权君合到每个像素位置。复杂度是位置个数的四次方。 对比输出特征矩阵之间的余弦距离可以发现不同位置得到的注意力矩阵相差不大。 MethodSimplify NL Block 简化：$\\mathbf{z}{i}=\\mathbf{x}{i}+\\sum_{j=1}^{N_{p}} \\frac{\\exp \\left(W_{k} \\mathbf{x}{j}\\right)}{\\sum{m=1}^{N_{p}} \\exp \\left(W_{k} \\mathbf{x}{m}\\right)}\\left(W{v} \\cdot \\mathbf{x}_{j}\\right)$ 进一步简化降低复杂度，将$W_{v}$移到注意力模块后，最后的卷积复杂度从O（HWC^2）降低到O（CxC）：$\\mathbf{z}{i}=\\mathbf{x}{i}+W_{v} \\sum_{j=1}^{N_{p}} \\frac{\\exp \\left(W_{k} \\mathbf{x}{j}\\right)}{\\sum{m=1}^{N_{p}} \\exp \\left(W_{k} \\mathbf{x}{m}\\right)} \\mathbf{x}{j}$ 上述公式的第二项直接建模全局信息，并直接叠加到原本的各个像素位置。将原本的NL块替换为简化后的版本，精度没有太大损失。 Global Context Modeling Framework 最简化的NL Block可分为三步 global attention pooling：通过$W_{k}$和Softmax得到注意力权重，完成全局注意力池化 feature transform： 1x1卷积$W_{v}$，建模通道间的依赖。 feature aggregation：每个元素累加全局特征 公式化：$\\mathbf{z}{i}=F\\left(\\mathbf{x}{i}, \\delta\\left(\\sum_{j=1}^{N_{p}} \\alpha_{j} \\mathbf{x}_{j}\\right)\\right)$，对应上图a。 SENet同样遵循上述流程。 Global Context Block 结合NL的长距离依赖和SE的轻量级优势 将SNL中的1x1卷积$W_{v}$替换为SE中的bottleneck减少计算量（CxC -&gt; 2 x C x C/r）RELU前添加layer norm。 另一个角度相当于将SE中的全局池化换成SNL的1x1卷积+softmax。 公式：$\\mathbf{z}{i}=\\mathbf{x}{i}+W_{v 2} \\operatorname{Re} \\mathrm{L} \\mathrm{U}\\left(\\mathrm{LN}\\left(W_{v 1} \\sum_{j=1}^{N_{p}} \\frac{e^{W_{k} \\mathbf{x}{j}}}{\\sum{m=1}^{N_{p}} e^{W_{k} \\mathbf{x}{m}}} \\mathbf{x}{j}\\right)\\right)$ 三步： 全局注意力池化 bottleneck捕捉通道间依赖 元素级加和聚合 GC-ResNet-50增加了9.89%的参数，0.26%的浮点运算。 实验 GC Block插入位置不敏感 在所有阶段使用好过单一阶段 池化-聚合的策略：att+add &gt; avg+add &gt; att+scale &gt; avg+scale (SE)","tags":[{"name":"CV","slug":"CV","permalink":"http://lossherl.github.io/tags/CV/"}]},{"title":"Aggregated Residual Transformations for Deep Neural Networks","date":"2020-03-15T13:14:48.000Z","path":"2020/03/15/2017 Aggregated Residual Transformations for Deep Neural Networks/","text":"Aggregated Residual Transformations for Deep Neural NetworksAbstract &amp; Introduction VGG模型展示一种简单高效的网络搭建策略：堆叠相同构造的block。ResNet继承了这一策略，减少了超参的可选度，使得网络深度成为一个需要重要考量的维度。作者认为这种简单的策略同时减少了过拟合数据集的风险。 Inception系列的网络通过精细设计网络拓扑，使得其能在低复杂度的情况下达到很高的准确率。在Inception模块中，一个核心的策略为split-transform-merge，输入先由1x1卷积分成多个低通道的嵌入，再分别经过一组变换（不同卷积核大小的卷积）后，连接得到结果。正是由这种策略达到高效且低计算复杂度。但是，精细设计的Inception模块中有很多超参（卷积核大小、个数等）需要设定，不易迁移到其他数据集。 本文贡献： 提出一个简单的网络架构，类似VGG/ResNet的堆叠相同层，同时以简单可扩展的形式利用split-transfrom-merge策略，各transform使用相同的拓扑结构，通过累加结果进行聚合，这种设计使得网络能够在不进行特殊改造的情况下扩展。 主张提升cardinality（Transform set的大小）是相比于宽提升度和深度更为高效的提升准确率的途径。 证实了在相同参数和计算量的情况下好过原本的ResNet。 MethodTemplate ResNeXt是通过堆叠残差块构成的。 这些残差块有着相同的拓扑结构，并遵循两个规则： 每个残差块输出相同大小的feature map，卷积核大小和个数相同。 每当feature map降采样为1/2，残差块宽度（通道数）乘以2。 AggregationSimple Neuron$$\\sum_{i=1}^{D} w_{i} x_{i}$$ ResNeXt$$\\mathbf{y}=\\mathbf{x}+\\sum_{i=1}^{C} \\mathcal{T}_{i}(\\mathbf{x})$$ Equivalent NotationResNeXt-50 (32×4d) 输入输出通道数为256，32x4d 指的是 32组3x3卷积核，每个卷积核的通道数为4， Experiment 相比于ResNet-50，32×4d ResNeXt-50的错误率降低了1.7%，同时随着Cardinalty从1增大到32，其错误率逐渐降低。且32×4d ResNeXt-50相比ResNet，训练错误了也低了很多，因此该模型的准确度提升并不是来源于正则化，而是在特征表达上得到了提升。 在维持复杂度不变的情况下，相比提升宽度和深度，提升基数对性能提升更好。","tags":[{"name":"CV","slug":"CV","permalink":"http://lossherl.github.io/tags/CV/"}]},{"title":"Attention Convolutional Binary Neural Tree for Fine-Grained Visual Categorization","date":"2020-03-14T11:20:48.000Z","path":"2020/03/14/2020 Attention Convolutional Binary Neural Tree for Fine-Grained Visual Categorization/","text":"Attention Convolutional Binary Neural Tree for Fine-Grained Visual Categorizationabstract 在树结构的边上结合卷积操作，使用路由方法定义叶子节点到根节点的计算路径，树的不同分支关注不同的局部区域，最终的预测结果为叶子节点的预测之和。 卷积操作用于捕捉目标的特征表示，树结构使得网络能够以由粗到细的层级模式进行特征学习。 使用attention transformer模块帮助网络捕捉具有高辨别力的区域。 Inspiration （Peng 2017）Object-part Attention model, 证实使用多个深度模型关注目标的不同区域是有效的 （Tanno 2019）类似本文的树结构方法，其中树结构随着学习进程推进增长。 Related Works Deep supervised methods （zhang 2014）双detector，在pose-normalized的特征表示上预测。 （Llu 2016）fully convolutional attention networks, glimpses local discriminative regions to adapt to different fine-grained domains （Huang 2016）part-stacked CNN architecture，对目标各part的细微差别建模。 这类方法依赖大量标注，限制了应用范围。 Deep weakly supervised methods （zheng 2017）Multi-attention CNN，part生成与特征学习互相促进。 （Fu 2017）recurrent attention module，在不同尺寸上递归学习高辨别度区域注意力和区域特征表示并互相促进。 （Sun 2018）使用多个目标part的注意力区域特征对不同输入图片的多个目标part进行约束（regulate）。 上述方法近将注意力进制与单网络结合。 决策树 解释性优势 （xiao 2017）神经决策树模型用于分类任务 （Frosst 2017）将深度神经决策树模型用于理解一个特定case的决策机制 本文结合决策树与神经网络同时实现分支选择和特征学习 注意力机制 级联注意力 通道注意力 结合区域注意力与特征矩阵注意力 本文在树结构的分支上应用注意力 Attention Convolution Binary Neural Tree ( ACNet )ACNet表示为二元组$(\\mathbb{T}, \\mathbb{O})$，$\\mathbb{T}$为树的拓扑，$\\mathbb{O}$为树边上的操作集合。$\\mathbb{T}={\\mathcal{V}, \\mathcal{E}},$ $\\mathcal{V}=\\left{v_{1}, \\cdots, v_{n}\\right}$ 为节点集合，$n$为节点个数， $\\mathcal{E}=\\left{e_{1}, \\cdots, e_{k}\\right}$为边的集合，由于树为二叉完全树，有$n=2^{h}-1$，$k=2^{h}-2$。树中的每个节点由路由模块产生，决定样本的传输分发路径。attention transform即边上的操作。 Backbone Network 由于细粒度分类中的高辨别度区域通常是局部的，因此需要小感受野（小步长、小池化核），因此使用VGG-16（Conv1_1 to Conv4_3），预训练于ILSVRC CLS-LOC数据集。 输入图像尺寸修改为448 x 448（原本224 x 224） 可使用其他网络作为主干 Branch Routing 用于确定样本接下来分发至左子树还是右子树 1x1卷积 -&gt; global context block（Non-local与Squeeze-Excitation的融合）-&gt; 全局平均池化 -&gt;元素平方根、L2正则化 -&gt; 全连接层、Sigmoid得到[0,1]值，对应左子树及右子树的概率。 Attention Transformer Module 在3x3卷积后插入注意力模块（如上图所示），产生通道注意力矩阵。 Label Prediction Module 由BN，1x1卷积、最大池化、平方根、L2政治则、全连接层组成。 最终预测$\\mathcal{C}\\left(x_{j}\\right)=\\sum_{i=1}^{2^{h-1}} \\mathcal{P}{i}\\left(x{j}\\right) r_{i}^{h}\\left(x_{j}\\right)$，其中$\\mathcal{P}{i}$为第i个叶子节点的分类概率，$r{i}^{k}\\left(x_{j}\\right)$为由根节点分发到第k层第i个节点的概率。 Trainning 数据增强 crop, flip 短边缩放到512像素 Loss Function $\\mathcal{L}=L\\left(\\mathcal{C}\\left(x_{j}\\right), y^{}\\right)+\\sum_{i=1}^{2^{n-1}} L\\left(\\mathcal{P}{i}\\left(x{j}\\right), y^{}\\right)$ 分为所有叶子节点的预测loss之和，最终预测loss两部分 优化 哈维初始化 前60轮fix VGG参数，之后finetune","tags":[{"name":"CV","slug":"CV","permalink":"http://lossherl.github.io/tags/CV/"}]},{"title":"Stacked capsule autoencoders","date":"2020-03-10T09:20:48.000Z","path":"2020/03/10/2019 Stacked capsule autoencodersmd/","text":"Stacked capsule autoencodersAbstract 物体是由一系列几何部分组成的 提出了无监督胶囊自编码器（SCAE），利用物体各部分（template）之间的几何关系对物体进行推理 这些几何关系与视角无关，因此提出的模型对视角变换具有鲁棒性。 SCEA由两个阶段组成 第一阶段：Part CAE直接从图像中预测各part template的presence与pose，并尝试通过arrange这些template以重构图像。 第二阶段：Object CAE预测一些物体胶囊的参数。首先组织此前发现part和pose得到一系列物体，再重构part和pose，其中inference是摊还的，且由现成的编码器实现。 与此前的胶囊网络不同 object capsule presences are highly informative of the object class，which leads to state-of-the-art results for unsupervised classification on SVHN (55%) and MNIST (98.7%). Introduction CNN效果好过无权重分享网络的原因在于CNN的归纳偏倚（Inductive Bias）：如果一个局部特征在某个图像区域中有效，那么该特征在其他位置也很可能有效。 当CNN试图探索视角变换的影响时，CNN则通过将特征复制成不同尺寸、方向、角度等，但此举很快导致冗长的高维的特征矩阵。 An alternative to replicating features across the non-translational degrees of freedom is to explicitly learn transformations between the natural coordinate frame of a whole object and the natural coordinate frames of each of its parts. 学习整体的坐标系和每个其各部分的坐标系之间的转换关系。计算机图形学就是就是以这样一种Object-&gt;part 坐标变换规则以获得具有视角不变性的几何体。人类的认知也是基于坐标系的。 用神经网络学习整体层面的变换是可行的，但是每种变换的表示都不尽想通。而整体与part之间的关系却是与视角无关的，近似于常数可以简单地用学习到的参数表示。 With this representation, the pose of a single object is represented by its relationship to the viewer. Consequently, representing a single object does not necessitate replicating neural activations across space, unlike in CNNs. It is only processing two (or more) different instances of the same type of object in parallel that requires spatial replicas of both model parameters and neural activations. Every object capsule contributes components to each of these mixtures by multiplying its pose—the object-viewer-relationship (OV)—by the relevant object-part-relationship (OP). SCAEConstellation AutoEncoder (CCAE) $\\left{\\mathbf{x}{m} | m=1, \\ldots, M\\right}$是输入的一个二维点集合，通过Set Transformer得到K个Object capsules，每一个capsule包含一个胶囊特征c，出现概率$a{k} \\in[0,1]$，以及Object-Viewer-relationship(OV)矩阵（表示物体（星座）和观察者的仿射变换）。 每一个胶囊各自用一个多层感知机根据c来预测N个候选part，出现概率a，标准差$\\lambda$以及OV矩阵。输入坐标建模为高斯混合，每个一元高斯的均值为$\\mu=OV\\times OP$，标准差为$\\lambda$。 使用无监督的方式训练，目标为最大化$p\\left(\\mathbf{x}_{1: M}\\right)$的极大似然 $$\\mathrm{OV}{1: K}, \\mathbf{c}{1: K}, a_{1: K}=\\mathrm{h}^{\\mathrm{caps}}\\left(\\mathbf{x}_{1: M}\\right) \\quad \\text { predict object capsule parameters }=$$ $$\\mathrm{OP}{k, 1: N}, a{k, 1: N}, \\lambda_{k, 1: N}=\\mathrm{h}{\\mathrm{k}}^{\\mathrm{part}}\\left(\\mathbf{c}{k}\\right) \\quad \\text { decode candidate parameters from } c_{k} \\text { ‘s}$$ $V_{k, n}=\\mathrm{OV}{k} \\mathrm{OP}{k, n} \\quad \\text { decode a part pose candidate } c_{k} \\text { ‘s } $$$p\\left(\\mathbf{x}{m} | k, n\\right)=\\mathcal{N}\\left(\\mathbf{x}{m} | \\mu_{k, n}, \\lambda_{k, n}\\right) \\quad \\text { turn candidates into mixture components }$$ $$p\\left(\\mathbf{x}{1: M}\\right)=\\prod{m=1}^{M} \\sum_{k=1}^{K} \\sum_{n=1}^{N} \\frac{a_{k} a_{k, n}}{\\sum_{i} a_{i} \\sum_{j} a_{i, j}} p\\left(\\mathbf{x}_{m} | k, n\\right)$$","tags":[{"name":"CV","slug":"CV","permalink":"http://lossherl.github.io/tags/CV/"}]},{"title":"hihoCoder 1364 奖券兑换","date":"2019-04-23T04:41:49.000Z","path":"2019/04/23/hihoCoder-1364-奖券兑换/","text":"时间限制:20000ms单点时限:1000ms内存限制:256MB描述小Hi在游乐园中获得了M张奖券，这些奖券可以用来兑换奖品。 可供兑换的奖品一共有N件。第i件奖品需要Wi张奖券才能兑换到，其价值是Pi。 小Hi使用不超过M张奖券所能兑换到的最大奖品总价值是多少？ 输入第一行两个整数N，M。 接下来N行，每行两个整数Wi，Pi。 对于 50%的数据： 1≤N,M≤1000 对于 100%的数据： 1≤N,M≤105,1≤Pi,Wi≤10。 输出一行一个整数，表示最大的价值。 样例输入3 102 38 810 10样例输出11 题目分析这道题一眼看去是个01背包问题。但是N和M范围都在10万，O(NM)的DP没办法在时限内出解。 进一步分析我们可以发现Wi和Pi的范围都很小，在10以内，所有本质上不同的奖品最多有100种，每种物品可能有很多件。 于是这道题又变成了一道多重背包问题。不过多重背包如果直接DP仍然是O(NM)的。这里我们介绍一种”二进制分解”的优化方法。 这种优化的思想是这样的：假设我有100件费用是W、价值的P的物品(用(W, P)表示)，意味着最优解可能从中选取0~100件。现在我把这100件(W, P)换成： 1) 1件(W, P)2) 1件(2W, 2P)3) 1件(4W, 4P)4) 1件(8W, 8P)5) 1件(16W, 16P)6) 1件(32W, 32P)7) 1件(37W， 37P) 一种7件物品。我们可以发现，假设最优解选择了K件(W, P)，无论K是多少，都可以通过选择以上7件中的若干件使得总费用和总价值也是(KW, KP)。换句话说，与最优解等价。反之，无论从7件中选取哪种组合，也都有一个K(0 &lt;= K &lt;= 100)与之对应，使得选择K件(W, P)的总费用和总价值与这种组合等价。 于是我们把100件相同的物品的背包，等价变成了7件不相同物品的背包。 具体来说，就是：假设有C件(W, P)，我们把C拆成尽可能多的2的幂之和以及剩余不足下一个2的幂的部分R，即C=1+2+4+8+…+2^K+R，其中R &lt; 2^(K+1)。 我们用(W, P), (2W, 2P), (4W, 4P), … (2^KW, 2^KP), (RW， RP)这K+2个物品代替原C个物品，新的背包问题与原问题是等价的。 将每种物品都做相同的二进制分解之后，对所有分解后得到的物品做01背包。 由于我们是把同类的C件物品分解成了O(logC)件物品。所以最大数据100种，总计10万件物品最多被分解成大约1000件物品。 使用01背包的DP，复杂度O(1000M)。 BTW多重背包还有一种使用单调队列优化的方法。大家感兴趣可以搜索相关的资料。","tags":[{"name":"题解","slug":"题解","permalink":"http://lossherl.github.io/tags/题解/"},{"name":"hihoCoder","slug":"hihoCoder","permalink":"http://lossherl.github.io/tags/hihoCoder/"}]},{"title":"Notes-Deep learning based RecSys utilizing visual content(3)","date":"2019-04-22T05:31:27.000Z","path":"2019/04/22/Notes-Deep-learning-based-RecSys-utilizing-visual-content-3/","text":"参考文献[1] Wu S, Tang Y, Zhu Y, et al. Session-based Recommendation with Graph Neural Networks[J]. arXiv preprint arXiv:1811.00855, 2018.(AAAI 2019) Session-based Recommendation with Graph Neural Networks介绍文章指出此前session-based的工作对序列进行建模以估计用户和物品的表示，尽管获得较好的效果，但不能得到准确的用户表示并在一定程度上忽略了浏览物品的变化过程。因此，作者提出了基于图神经网络的SR-GNN模型，将每个session建模成图的形式，用GNN获得各个物品的表示，再通过注意力网络获得每个session的表示，从而该表示融合了全局的偏好和当前session兴趣的信息，最后为每个session预测各物品下次点击的概率。模型架构如图1所示。 方法描述 GNN模型将各序列单独建成有向图，由于序列中某个物品可能出现多次，故将边的权值设为边的出现次数除以边起点的出度，最终每个序列得到一个如图2所示n*2n的连接矩阵A。随后，将每个序列一一送入GNN中，获得各个物品的向量表示，GNN更新公式如公式1，2，3，4，5。公式1抽取相邻节点的向量表示，作为GNN的输入；公式2，3对应更新门和重置门的更新方法；公式4根据当前状态，上一时刻状态以及当前更新门状态产生候选状态；公式5结合上一时刻状态和候选状态，在更新门的控制下生成当前时刻状态。 生成序列表示此前session-based的方法往往假设对应每个序列的用户都存在独立的表示，而SR-GNN中的序列表示直接由序列中的顶点表示产生。序列表示为短期兴趣和长期偏好的结合，其中短期兴趣简单地设为序列中最后一个物品的向量表示，长期偏好通过soft注意力机制产生，最终的序列表示通过短期兴趣和长期偏好表示连接后经过线性变换得到。 生成推荐以及训练方法得到序列表示后，将序列表示乘以每个候选物品的向量得到得分z，再由softmax计算每个候选物品的概率。训练采用交叉熵作为损失函数，BPTT(Back-Propagation Through Time)更新参数。模型时间复杂度为O(m^2 * n)，其中m为平均序列长度，n为总体序列个数，实际上，m远小于n，因此模型复杂度接近线性。部署时，分为在线离线两个部分，离线计算每个物品的表示，从而在线计算推荐结果， 实验实验中验证了：引入深度学习的有效性；基于马尔可夫链的模型的独立假设（仅基于上一状态）不可靠；注意力机制能更好地忽略噪声、表现长期的偏好；图建模的有效性。 不同建图方式的比较将各个序列聚合成全局图：由于权值的存在，降低了自身序列中高度节点边的重要性，影响了序列整体性，当权值变化时，模型表现下降。添加高阶节点间的连接：效果变差，并不是所有高阶节点都应该直接相连，中继节点有存在的必要。 不同序列表示的比较证实了短期兴趣与长期偏好结合的必要；序列中噪声影响较大。 序列长度分析实验将数据集根据序列长度阈值5分割为短序列、长序列两个部分。NARM和STAMP模型面向长序列时表现下降，可能的原因分别是忽略了重复动作以及RNN面向长序列的困难。","tags":[{"name":"RecSys","slug":"RecSys","permalink":"http://lossherl.github.io/tags/RecSys/"},{"name":"User preference modeling","slug":"User-preference-modeling","permalink":"http://lossherl.github.io/tags/User-preference-modeling/"}]},{"title":"Notes-Deep learning based RecSys utilizing visual content(2)","date":"2019-04-09T08:10:25.000Z","path":"2019/04/09/Notes-Deep-learning-based-RecSys-utilizing-visual-content-2/","text":"参考文献[1] Li Z, Zhao H, Liu Q, et al. Learning from history and present: Next-item recommendation via discriminatively exploiting user behaviors[C]//Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. ACM, 2018: 1734-1743.[2] Grbovic M, Cheng H. Real-time personalization using embeddings for search ranking at Airbnb[C]//Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. ACM, 2018: 311-320. Learning from History and Present: Next-item Recommendation via Discriminatively Exploiting User Behaviors介绍电子商务中，顾客的行为包含了大量信息，包括消费习惯，变化的偏好等，session-based的推荐越来越流行。文章指出现有研究工作仅关注了短期内的行为，忽略了用户的长期偏好和演化过程。提出了Behavior-Intensive Neural Network(BINN)，通过结合用户的长期偏好和当前消费动机对下一件访问的物品进行推荐。模型包含两个组件，其一是基于用户交互用于获得物品统一表示的嵌入方法，其二是基于嵌入物品以及交互序列的判别行为学习，学习目标用户历史偏好和当前动机。图1展示了文章的思想。与传统基于文本或图片的嵌入方法不同，文章中提出的嵌入方法直接利用用户与物品的交互序列。对于第二个组件，文章中用两个深层网络共同地学习用户的当前动机与历史偏好。最终，候选物品也映射到同一隐空间中，由BINN为用户生成推荐，整体结构如图2所示。 物品嵌入方法(w-item2vec)w-item2vec通过物品访问序列习得物品间的相似度，从而得到每个物品的向量表示，核心思想是表现出相似吸引性（访问序列相似）的物品往往很相似。受Item2vec启发，w-item2vec也使用了Skip-gram model with Negative Sampling，w-item2vec中的Skip-gram最大化的目标函数如公式1，加入负采样，并将物品在序列中的频度作为采样权重后，最终的目标函数如公式5所示，其中w为物品的向量表示，v为上下文物品的向量表示。 Discriminative Behaviors Learning该组件包含两个基于LSTM的网络，用于学习用户的短期动机和长期偏好。两个网络的输出经过一个全连接层后生成一个d维向量，为下件物品进行推荐。 Session Behaviors Learning(SBL)如图2所示，SBL中的每一个隐状态由上一时刻隐状态、当前物品向量、交互动作(one-hot向量)更新，ts指示session的长度，默认为10，最终SBL的输出为t-1时刻的隐状态。 Preference Behaviors Learning(PBL)该网络试图对用户长期的偏好进行建模，考虑用户历史偏好物品（添加购物车、购买、收藏等）。由于长期偏好波动不大，因此SBL的网络结果不适用于PBL，PBL采用了类似双向LSTM的结构，更新方式与SBL类似。每个时刻的隐状态由前向和后向的隐状态向量连接得到，PBL最终输出为各时刻的隐状态均值。 模型训练训练采用均方误差作为损失函数，如公式10所示。生成k维向量v后，在嵌入空间中计算v与其他物品表示的相似度，将最相似的前k个物品作为推荐。 实验实验采用了京东和天池数据集。由于加入了频度作为负采样权重，w-item2vec的表现优于item2vec。评测尺度采用Recall@20和MRR@20，根据与其他模型的比较实验结果，强调了对用户长期偏好进行建模的有效性。对于冷启动问题，实验中用预训练的模型fit新用户，从第二个交互开始预测，实验中发现深度学习模型能够较好地面对冷启动现象。此外，在对用户历史偏好建模分析中，利用的历史交互次数越多模型表现越好。 天池数据集：https://tianchi.aliyun.com/competition/entrance/231522/information Real-time Personalization using Embeddings for Search Ranking at Airbnb介绍文章中的应用场景是双向的，例如在预定民宿时，算法需要同时优化租户与房东的要求。作者同时考虑了用户的短期浏览行为和长期偏好，在个体与类型两个层面做嵌入，分别是利用用户短期的浏览行为对民宿做向量化，以及利用用户的历史预定序列学习用户类型和民宿类型在同一隐空间的向量表示。 方法民宿嵌入 给定由N个用户的短期浏览行为序列组成的集合S，基于skip-gram模型学习每个民宿的向量表示，由于民宿集合过大，应用负采样方法降低计算复杂度，正向样本对包括用户访问过的民宿和对应民宿在访问序列中的相邻民宿，负向样本对包含用户访问过的民宿以及n个随机采样的民宿。进一步将浏览序列分为两类，一类为以预定结束的浏览序列，另一类是未以预定做结尾的浏览序列。最终预定的民宿可作为全局context，从而第一类浏览序列里的每个民宿不仅预测相邻民宿，还对最终预定的民宿做预测，过程如图1所示。由于用户每次浏览的通常都是位于同一区域的民宿，因此正向样本中相邻的民宿往往在同一区域中，而负向样本序列是随机采样的，不具有这一性质。该不平衡现象将导致次优的局域民宿相似度，为解决该问题，为序列中国的每个民宿添加一个局域随机采样的负样本集合。最终，目标函数如公式5所示。为解决冷启动问题，作者选择3所与新加入的民宿距离最近且类型相同租金相近的有向量表示的民宿，对这三所民宿的向量化表示取平均值作为新民宿的向量表示，此举解决了98%的新民宿表示问题。 民宿类型与用户类型嵌入 除短期浏览行为意外，用户的长期偏好对个性化推荐也具有重要意义，但是，用户的订单数据十分稀疏，因此，作者对用户类型和民宿类型进行建模。对于民宿类型划分，根据民宿类型、租金、面积等属性，通过基于规则的方法将每个民宿多对一地映射到某个民宿类型。用户类型的划分也使用类似民宿的基于规则的方法，值得注意的是，民宿类型与用户类型可能随属性改变而变化。为在同一空间表示用户类型和民宿类型，作者将用户类型加入了预定序列，训练过程如图5所示，预定序列由多个预定事件按时间顺序连接组成，预定事件为（用户类型、民宿类型）二元组。训练方法与民宿嵌入类似，同样基于skip-gram模型，目标函数取决于位于滑动窗口中心的元素为用户类型或民宿类型。与民宿嵌入不同的是，该序列已包含跨区域的预定事件，因此无需添加跨区域负采样。 不同于浏览行为仅反映用户偏好，预定事件还包含了房东偏好信息，在训练过程中利用房东的拒绝事件可以在嵌入向量中反映房东的偏好。由于一些类型的民宿对信息不全，历史订单少的用户类型不敏感，作者希望这类民宿与用户类型更近，从而提高未来的预定成功率。因此，训练时添加了一类拒绝事件集合，包含（用户类型，民宿类型）二元组，主要关注预定失败后预定成功的情况。最终用户类型和民宿类型的目标函数如公式8，9所示。 实验作者利用得到的民宿向量、用户类型向量和民宿类型向量，与用户近期浏览的民宿（根据不同喜好程度分多个类别）计算相似度，得到多个相似度特征表示，最终将特征加入GBDT搜索排序模型中完成排序。","tags":[{"name":"RecSys","slug":"RecSys","permalink":"http://lossherl.github.io/tags/RecSys/"},{"name":"User preference modeling","slug":"User-preference-modeling","permalink":"http://lossherl.github.io/tags/User-preference-modeling/"}]},{"title":"Notes-Deep learning based RecSys utilizing visual content(1)","date":"2019-04-04T02:02:03.000Z","path":"2019/04/04/Notes-Deep-learning-based-RecSys-utilizing-visual-content-1/","text":"参考文献[1] Zhou J, Albatal R, Gurrin C. Applying Visual User Interest Profiles for Recommendation and Personalisation.[J]. 2016. (MMM)[2] Lei C , Liu D , Li W , et al. Comparative Deep Learning of Hybrid Representations for Image Recommendations[J]. 2016. (CVPR) Applying Visual User Interest Profiles for Recommendation and Personalisation介绍文献[1]认为用户的兴趣偏好可以从其曾经发布的照片中获取，通过使用深度学习中的技术从图片集中获取用户的视觉偏好信息，并用于酒店推荐及页面个性化定制。 视觉特征提取在基于内容的图片检索领域中，一些诸如颜色、文本等低级语义信息被用于表示图像以及计算图像相似度，但是这些低级语义并不能很好地表示用户偏好。文献[1]假设通过结合深度学习，对用户特征进行更高语义层面的提取将使得基于内容的推荐更加有效。文章中的方法利用AlexNet对图像作特征提取，将分类结果（1000个类别的概率分布）作为图像特征。 利用用户偏好文章使用余弦距离作图片间的相似度估计，如公式(1)所示。因此，通过计算用户偏好档案中的图像特征向量与其余图像的特征向量的相似度，获得与用户偏好相近的图片。用户偏好档案由多个图像的特征表示组成。 应用应用于酒店推荐以及酒店页面个性化定制,推荐最近邻图片对应的酒店，没有相关实验结果介绍。 Comparative Deep Learning of Hybrid Representations for Image Recommendations介绍诸如图片推荐等以用户为中心的任务不仅需要高效的图片表示，还需要对用户的偏好和意图进行表示。文章提出的方法将用户和图片映射到同一隐空间中，再通过计算图片表示与用户表示的距离做决策。文章还提出一种名为比较深度学习(CDL)的方法，在不增加额外计算代价的前提下，使用了更多的训练数据，取得了比传统训练方法更好的效果，超越了state of the art图片推荐系统。文章提出的模型包含两个深度网络，分别抽取图片和用户偏好表示，CDL方法使用三元组(用户、正例图片，反例图片)做输入，学习正反例照片的相对距离，如图1所示。 相关研究图片表示学习 有监督哈希方法，在深度学习框架下同时学习哈希函数和图片表示。 深度学习模型（图片分类模型）的中层输出。 对于以用户为中心的应用，不仅需要考虑图片表示，用户的偏好也具有极大价值。 同时考虑图片相似度和用户的社交关系学习一种新的距离度量，但需要精细的人工特征选择。 以用户间的相似度对用户意图进行建模。 以三元组进行训练的效果好过单一图片。 个性化图片推荐 结合当地社区用户评分的概率矩阵分解方法。 使用双因素回归的矩阵分解方法捕获用户社交属性上述方法仅关注用户的行为模式忽略了图片因素。 结合用户偏好和上传照片的主题模型，用于学习社交网络中用户的影响力。 基于社交嵌入的图片表示的投票方法。 比较学习在社交网络中，用户对于图片的负向反馈十分匮乏，因此，使用传统方法训练的效果十分受限。文章中提出的比较学习方法，以公式1所示的三元组集合作为输入，目标是习得图片和用户偏好的映射函数，满足公式2，即相对反例图片，用户偏好向量与正例图片的向量表示的距离更近。其中距离尺度可以是简单的欧几里得距离，为了使正反例图片表示的距离尽可能地远，进一步采用交叉熵作为损失函数，相关定义如公式3，4，5。 双网络结构如图2所示，上方与下方的网络分别用于抽取正反例图片的表示，有着相同定义(类似AlexNet)并共享参数。中间的网络用于捕获用户的偏好信息，由多个全连接层组成，网络的输入向量需要人为的特征选择。使用CDL方法的有两个需要解决的问题，一是如何对用户数据进行预处理生成输入用户向量，二是如何准备训练集中的三元组。对于第一个问题，由于用户标签过于稀疏，文章中采用的方法是将标签通过word2vec映射成向量，再将所有标签向量通过k均值算法聚成1024个聚类，因此用户可以表示成1024维的向量。对于第二个问题，正例图片可通过用户点赞行为获取，对于反例图片，因为用户未点赞的图片未必是用户不喜欢的（可能从未见过），文章中通过融入社交关系，从作者未点赞的图片和好友社区也未点赞的图片集中采样反例图片，从而生成训练所需的三元组。推荐时，首先选择一个候选集，候选集中的图片至少拥有一个用户喜好的标签，然后将用户与图片同时映射到同一隐空间中，用K近邻算法获取推荐图片列表。 实验实验使用在Flickr上爬取的数据集，包含101496张图片，54173个用户，6439个群组，35844个图片标签，平均每位用户有23.5给喜好标签和5.8张点赞图片。由于数据集过于稀疏，无法使用如协同过滤等传统算法进行推荐，故未与此类算法进行比较。比较实验结果如图5，6所示，由实验结果可见应用交叉熵损失的CDL效果好过使用铰链损失，基于人工特征提取的BoW和LMNN方法表现极差，BoW预测精度接近随机猜测，应用ImageNet特征的SIDL取得了第三好的结果，体现了深度学习的优势。通过融入社交信息，LMNN的表现提高显著。","tags":[{"name":"RecSys","slug":"RecSys","permalink":"http://lossherl.github.io/tags/RecSys/"},{"name":"User preference modeling","slug":"User-preference-modeling","permalink":"http://lossherl.github.io/tags/User-preference-modeling/"}]},{"title":"hihoCoder 1290 Demo Day","date":"2017-03-22T16:25:25.000Z","path":"2017/03/23/hihoCoder-1290-Demo-Day/","text":"描述You work as an intern at a robotics startup. Today is your company’s demo day. During the demo your company’s robot will be put in a maze and without any information about the maze, it should be able to find a way out. The maze consists of N * M grids. Each grid is either empty(represented by ‘.’) or blocked by an obstacle(represented by ‘b’). The robot will be release at the top left corner and the exit is at the bottom right corner. Unfortunately some sensors on the robot go crazy just before the demo starts. As a result, the robot can only repeats two operations alternatively: keep moving to the right until it can’t and keep moving to the bottom until it can’t. At the beginning, the robot keeps moving to the right. rrrrbb..…r…. ====&gt; The robot route with broken sensors is marked by ‘r’.…rrb..…bb…While the FTEs(full-time employees) are busy working on the sensors, you try to save the demo day by rearranging the maze in such a way that even with the broken sensors the robot can reach the exit successfully. You can change a grid from empty to blocked and vice versa. So as not to arouse suspision, you want to change as few grids as possible. What is the mininum number? 输入Line 1: N, M. Line 2-N+1: the N * M maze. For 20% of the data, N * M &lt;= 16. For 50% of the data, 1 &lt;= N, M &lt;= 8. For 100% of the data, 1&lt;= N, M &lt;= 100. 输出The minimum number of grids to be changed. 样例输入4 8….bb..……..…..b..…bb…样例输出1 思路： 动态规划，dp[i][j][k]表示到达(i,j)点以k方向前进最小所需做改变的次数。 代码: #include &lt;iostream&gt; using namespace std; int m,n; bool map[110][110] = {0}; int dp[110][110][2] = {0}; int main() { cin &gt;&gt; n &gt;&gt; m; for(int i = 1; i &lt;= n; i++) { for(int j = 1; j &lt;= m; j++) { char c; cin &gt;&gt; c; if(c == &apos;.&apos;) { map[i][j] = true; } } } for(int i = 0; i &lt;= n; i++) { for(int j = 0; j &lt;= m; j++) { dp[i][j][0] = dp[i][j][1] = 999999; } } dp[1][1][0] = 0; for(int i = 1; i &lt;= n; i++) { for(int j = 1; j &lt;= m; j++) { for(int k = 0; k &lt; 2; k++) { if(map[i][j]) { if(k) { dp[i][j][k] = min(dp[i][j][k],dp[i - 1][j][k]); if(!map[i + 1][j]) { dp[i][j][1 - k] = min(dp[i][j][1 - k],dp[i][j][k]); } else { dp[i][j][1 - k] = min(dp[i][j][1 - k],dp[i][j][k] + 1); } } else { dp[i][j][k] = min(dp[i][j][k],dp[i][j - 1][k]); if(!map[i][j + 1]) { dp[i][j][1 - k] = min(dp[i][j][1 - k],dp[i][j][k]); } else { dp[i][j][1 - k] = min(dp[i][j][1 - k],dp[i][j][k] + 1); } } } else { if(k) { dp[i][j][k] = min(dp[i][j][k],dp[i - 1][j][k] + 1); if(!map[i + 1][j]) { dp[i][j][1 - k] = min(dp[i][j][1 - k],dp[i][j][k]); } else { dp[i][j][1 - k] = min(dp[i][j][1 - k],dp[i][j][k] + 1); } } else { dp[i][j][k] = min(dp[i][j][k],dp[i][j - 1][k] + 1); if(!map[i][j + 1]) { dp[i][j][1 - k] = min(dp[i][j][1 - k],dp[i][j][k]); } else { dp[i][j][1 - k] = min(dp[i][j][1 - k],dp[i][j][k] + 1); } } } // cout &lt;&lt; i &lt;&lt; &quot; &quot; &lt;&lt; j &lt;&lt; &quot; &quot; &lt;&lt; k &lt;&lt; &quot; &quot; &lt;&lt; dp[i][j][k] &lt;&lt; endl; } } } cout &lt;&lt; min(dp[n][m][0],dp[n][m][1]) &lt;&lt; endl; }","tags":[{"name":"题解","slug":"题解","permalink":"http://lossherl.github.io/tags/题解/"},{"name":"hihoCoder","slug":"hihoCoder","permalink":"http://lossherl.github.io/tags/hihoCoder/"}]},{"title":"hihoCoder 1238 Total Highway Distance","date":"2017-03-21T14:28:30.000Z","path":"2017/03/21/hihoCoder-1238-Total-Highway-Distance/","text":"时间限制:10000ms单点时限:1000ms内存限制:256MB描述Little Hi and Little Ho are playing a construction simulation game. They build N cities (numbered from 1 to N) in the game and connect them by N-1 highways. It is guaranteed that each pair of cities are connected by the highways directly or indirectly. The game has a very important value called Total Highway Distance (THD) which is the total distances of all pairs of cities. Suppose there are 3 cities and 2 highways. The highway between City 1 and City 2 is 200 miles and the highway between City 2 and City 3 is 300 miles. So the THD is 1000(200 + 500 + 300) miles because the distances between City 1 and City 2, City 1 and City 3, City 2 and City 3 are 200 miles, 500 miles and 300 miles respectively. During the game Little Hi and Little Ho may change the length of some highways. They want to know the latest THD. Can you help them? 输入Line 1: two integers N and M. Line 2 .. N: three integers u, v, k indicating there is a highway of k miles between city u and city v. Line N+1 .. N+M: each line describes an operation, either changing the length of a highway or querying the current THD. It is in one of the following format. EDIT i j k, indicating change the length of the highway between city i and city j to k miles. QUERY, for querying the THD. For 30% of the data: 2&lt;=N&lt;=100, 1&lt;=M&lt;=20 For 60% of the data: 2&lt;=N&lt;=2000, 1&lt;=M&lt;=20 For 100% of the data: 2&lt;=N&lt;=100,000, 1&lt;=M&lt;=50,000, 1 &lt;= u, v &lt;= N, 0 &lt;= k &lt;= 1000. 输出For each QUERY operation output one line containing the corresponding THD. 样例输入3 51 2 22 3 3QUERYEDIT 1 2 4QUERYEDIT 2 3 2QUERY样例输出101412 思路： 两次深搜计算每条路径经过的次数。 代码： #include &lt;iostream&gt; #include &lt;vector&gt; #include &lt;queue&gt; #include &lt;cmath&gt; #include &lt;algorithm&gt; #include &lt;cstring&gt; #include &lt;string&gt; #include &lt;cstdio&gt; using namespace std; typedef struct p{ int cur; vector&lt;int&gt; v; p(int c) { cur = c; } }p; typedef struct ar{ int to; int index; ar(int t,int i) { to = t; index = i; } }ar; typedef struct arcc{ int f; int t; int v; }arcc; vector&lt;ar&gt; a[100010]; bool vi[100010] = {0}; arcc arc[100010]; long long arc_c[100010] = {0}; int n,m; int child[100010] = {0}; long long query() { long long ans = 0; for(int i = 1; i &lt; n; i++) { ans += arc[i].v * arc_c[i]; } return ans; } void dfs(int x,int f) { child[x] = 1; for(int i = 0; i &lt; a[x].size(); i++) { if(a[x][i].to == f) continue; dfs(a[x][i].to,x); child[x] += child[a[x][i].to]; } } void dfs1(int x,int f) { for(int i = 0; i &lt; a[x].size(); i++) { if(a[x][i].to == f) continue; arc_c[a[x][i].index] = (long long) child[a[x][i].to] * (long long)(n - child[a[x][i].to]); dfs1(a[x][i].to,x); } } int main() { cin &gt;&gt; n &gt;&gt; m; for(int i = 1; i &lt; n; i++) { int f,t,v; scanf(&quot;%d %d %d&quot;,&amp;f,&amp;t,&amp;v); arc[i].v = v; arc[i].f = f; arc[i].t = t; a[f].push_back(ar(t,i)); a[t].push_back(ar(f,i)); } dfs(1,0); dfs1(1,0); // for(int i = 1; i &lt; n; i++) // cout &lt;&lt; arc_c[i] &lt;&lt; endl; string cmd; long long ans = query(); for(int i = 1; i &lt;= m; i++) { cin &gt;&gt; cmd; if(cmd == &quot;QUERY&quot;) { printf(&quot;%lld\\n&quot;,ans); } else { int f,t,v; scanf(&quot;%d %d %d&quot;,&amp;f,&amp;t,&amp;v); for(int j = 0; j &lt; a[f].size(); j++) { if(a[f][j].to == t) { ans += arc_c[a[f][j].index] * (v - arc[a[f][j].index].v); arc[a[f][j].index].v = v; break; } } } } }","tags":[{"name":"题解","slug":"题解","permalink":"http://lossherl.github.io/tags/题解/"},{"name":"hihoCoder","slug":"hihoCoder","permalink":"http://lossherl.github.io/tags/hihoCoder/"}]},{"title":"hihoCoder 1399 Shortening Sequence","date":"2017-03-21T14:25:14.000Z","path":"2017/03/21/hihoCoder-1399-Shortening-Sequence/","text":"时间限制:10000ms单点时限:1000ms内存限制:256MB描述There is an integer array A1, A2 …AN. Each round you may choose two adjacent integers. If their sum is an odd number, the two adjacent integers can be deleted. Can you work out the minimum length of the final array after elaborate deletions? 输入The first line contains one integer N, indicating the length of the initial array. The second line contains N integers, indicating A1, A2 …AN. For 30% of the data：1 ≤ N ≤ 10 For 60% of the data：1 ≤ N ≤ 1000 For 100% of the data：1 ≤ N ≤ 1000000, 0 ≤ Ai ≤ 1000000000 输出One line with an integer indicating the minimum length of the final array. 样例提示(1,2) (3,4) (4,5) are deleted. 样例输入71 1 2 3 4 4 5样例输出1 思路： 动态规划，线性扫描并枚举26个字母。 代码: #include &lt;iostream&gt; #include &lt;vector&gt; #include &lt;algorithm&gt; #include &lt;cmath&gt; #include &lt;cstdio&gt; using namespace std; //strucc p{ // int cur; // int last; // int len; //}dp[1000001]; int n; int main() { cin &gt;&gt; n; vector&lt;int&gt; v; int t; scanf(&quot;%d&quot;,&amp;t); v.push_back(t); for(int i = 2; i &lt;= n; i++) { scanf(&quot;%d&quot;,&amp;t); if(v.size() == 0) { v.push_back(t); continue; } if((t ^ v[v.size() - 1]) &amp; 1) { v.erase(v.end() - 1); } else v.push_back(t); } cout &lt;&lt; v.size(); }","tags":[{"name":"题解","slug":"题解","permalink":"http://lossherl.github.io/tags/题解/"},{"name":"hihoCoder","slug":"hihoCoder","permalink":"http://lossherl.github.io/tags/hihoCoder/"}]},{"title":"hihoCoder 1288 Font Size","date":"2017-03-21T14:21:08.000Z","path":"2017/03/21/hihoCoder-1288-Font-Size/","text":"时间限制:10000ms单点时限:1000ms内存限制:256MB描述Steven loves reading book on his phone. The book he reads now consists of N paragraphs and the i-th paragraph contains ai characters. Steven wants to make the characters easier to read, so he decides to increase the font size of characters. But the size of Steven’s phone screen is limited. Its width is W and height is H. As a result, if the font size of characters is S then it can only show ⌊W / S⌋ characters in a line and ⌊H / S⌋ lines in a page. (⌊x⌋ is the largest integer no more than x) So here’s the question, if Steven wants to control the number of pages no more than P, what’s the maximum font size he can set? Note that paragraphs must start in a new line and there is no empty line between paragraphs. 输入Input may contain multiple test cases. The first line is an integer TASKS, representing the number of test cases. For each test case, the first line contains four integers N, P, W and H, as described above. The second line contains N integers a1, a2, … aN, indicating the number of characters in each paragraph. For all test cases, 1 &lt;= N &lt;= 103, 1 &lt;= W, H, ai &lt;= 103, 1 &lt;= P &lt;= 106, There is always a way to control the number of pages no more than P. 输出For each testcase, output a line with an integer Ans, indicating the maximum font size Steven can set. 样例输入21 10 4 3102 10 4 310 10样例输出32 思路： 二分搜索。 代码： #include &lt;iostream&gt; #include &lt;vector&gt; #include &lt;algorithm&gt; #include &lt;cmath&gt; #include &lt;cstdio&gt; #include &lt;cstring&gt; #include &lt;string&gt; #include &lt;queue&gt; using namespace std; int task; int w,h,p; int n; int a[1001] = {0}; int main() { cin &gt;&gt; task; for(int z = 1; z &lt;= task; z++) { cin &gt;&gt; n &gt;&gt; p &gt;&gt; w &gt;&gt; h; for(int i = 1; i &lt;= n; i++) cin &gt;&gt; a[i]; int l = 1; int r = min(w,h); int mid; int last; while(l &lt;= r) { mid = (l + r) / 2; int line = h / mid; int wid = w / mid; int count = 0; for(int j = 1; j &lt;= n; j++) { count += a[j] / wid; if(a[j] % wid) count++; } if(count &lt;= p * line) { last = mid; l = mid + 1; } else { r = mid - 1; } } cout &lt;&lt; last &lt;&lt; endl; } }","tags":[{"name":"题解","slug":"题解","permalink":"http://lossherl.github.io/tags/题解/"},{"name":"hihoCoder","slug":"hihoCoder","permalink":"http://lossherl.github.io/tags/hihoCoder/"}]},{"title":"蓝桥杯 历届试题 小朋友排队","date":"2017-03-17T15:04:42.000Z","path":"2017/03/17/蓝桥杯-历届试题-小朋友排队/","text":"问题描述 n 个小朋友站成一排。现在要把他们按身高从低到高的顺序排列，但是每次只能交换位置相邻的两个小朋友。 每个小朋友都有一个不高兴的程度。开始的时候，所有小朋友的不高兴程度都是0。 如果某个小朋友第一次被要求交换，则他的不高兴程度增加1，如果第二次要求他交换，则他的不高兴程度增加2（即不高兴程度为3），依次类推。当要求某个小朋友第k次交换时，他的不高兴程度增加k。 请问，要让所有小朋友按从低到高排队，他们的不高兴程度之和最小是多少。 如果有两个小朋友身高一样，则他们谁站在谁前面是没有关系的。输入格式 输入的第一行包含一个整数n，表示小朋友的个数。 第二行包含 n 个整数 H1 H2 … Hn，分别表示每个小朋友的身高。输出格式 输出一行，包含一个整数，表示小朋友的不高兴程度和的最小值。样例输入33 2 1样例输出9样例说明 首先交换身高为3和2的小朋友，再交换身高为3和1的小朋友，再交换身高为2和1的小朋友，每个小朋友的不高兴程度都是3，总和为9。数据规模和约定 对于10%的数据， 1&lt;=n&lt;=10； 对于30%的数据， 1&lt;=n&lt;=1000； 对于50%的数据， 1&lt;=n&lt;=10000； 对于100%的数据，1&lt;=n&lt;=100000，0&lt;=Hi&lt;=1000000。 思路： 逆序数+树状数组，每个点左边大于它的个数加上右边小于它的个数等于交换的总次数，使用树状数组统计。 AC代码： #include &lt;iostream&gt; using namespace std; #define N 100100 #define MAX 1000100 int a[MAX] = {0}; int b[MAX] = {0}; int c[N] = {0}; int num[N] = {0}; long long total[N] = {0}; int n; int lowbit(int x) { return x&amp;(-x); } void add(int pos,int *p) { while(pos &lt;= MAX) { p[pos]++; pos += lowbit(pos); } } int sum(int pos,int *p) { int cnt = 0; while(pos &gt; 0) { cnt += p[pos]; pos -= lowbit(pos); } return cnt; } void Init() { for(int i = 1; i &lt;= n; i++) { total[i] = total[i - 1] + i; } } int main() { cin &gt;&gt; n; Init(); for(int i = 0; i &lt; n; i++) { cin &gt;&gt; num[i]; add(num[i] + 1,a); c[i] = i - sum(num[i],a); c[i] -= sum(num[i] + 1,a) - sum(num[i],a) - 1; } long long ans = 0; for(int i = n - 1; i &gt;= 0; i--) { add(num[i] + 1,b); c[i] += sum(num[i],b); ans += total[c[i]]; } cout &lt;&lt; ans; }","tags":[{"name":"题解","slug":"题解","permalink":"http://lossherl.github.io/tags/题解/"},{"name":"蓝桥杯","slug":"蓝桥杯","permalink":"http://lossherl.github.io/tags/蓝桥杯/"}]},{"title":"蓝桥杯 历届试题 高僧斗法","date":"2017-03-17T15:00:48.000Z","path":"2017/03/17/蓝桥杯-历届试题-高僧斗法/","text":"问题描述 古时丧葬活动中经常请高僧做法事。仪式结束后，有时会有“高僧斗法”的趣味节目，以舒缓压抑的气氛。 节目大略步骤为：先用粮食（一般是稻米）在地上“画”出若干级台阶（表示N级浮屠）。又有若干小和尚随机地“站”在某个台阶上。最高一级台阶必须站人，其它任意。(如图1所示) 两位参加游戏的法师分别指挥某个小和尚向上走任意多级的台阶，但会被站在高级台阶上的小和尚阻挡，不能越过。两个小和尚也不能站在同一台阶，也不能向低级台阶移动。 两法师轮流发出指令，最后所有小和尚必然会都挤在高段台阶，再也不能向上移动。轮到哪个法师指挥时无法继续移动，则游戏结束，该法师认输。 对于已知的台阶数和小和尚的分布位置，请你计算先发指令的法师该如何决策才能保证胜出。 输入格式 输入数据为一行用空格分开的N个整数，表示小和尚的位置。台阶序号从1算起，所以最后一个小和尚的位置即是台阶的总数。（N&lt;100, 台阶总数&lt;1000）输出格式 输出为一行用空格分开的两个整数: A B, 表示把A位置的小和尚移动到B位置。若有多个解，输出A值较小的解，若无解则输出-1。样例输入1 5 9样例输出1 4样例输入1 5 8 10样例输出1 3 思路： Nim游戏的变形，每个小和尚之间的台阶即为Nim游戏中的单堆石子数。 AC代码： #include &lt;iostream&gt; using namespace std; int a[101] = {0}; int b[101] = {0}; int main() { int i; int n; int sum = 0; while(cin &gt;&gt; i) { n++; a[n] = i; } for(i = 1; i &lt;= n / 2; i++) { b[i] = a[2 * i] - a[2 * i - 1] - 1; } for(i = 1; i &lt;= n / 2; i++) { sum ^= b[i]; } if(sum == 0) cout &lt;&lt; -1; else { for(i = 1; i &lt;= n; i++) { for(int j = 1; j &lt; a[i + 1] - a[i]; j++) { a[i] += j; sum = 0; for(int k = 1; k &lt;= n / 2; k++) { b[k] = a[2 * k] - a[2 * k - 1] - 1; sum ^= b[k]; } if(sum == 0) { cout &lt;&lt; a[i] - j &lt;&lt; &quot; &quot; &lt;&lt; a[i] &lt;&lt; endl; break; } a[i] -= j; } } } }","tags":[{"name":"题解","slug":"题解","permalink":"http://lossherl.github.io/tags/题解/"},{"name":"蓝桥杯","slug":"蓝桥杯","permalink":"http://lossherl.github.io/tags/蓝桥杯/"}]},{"title":"蓝桥杯 历届试题 国王的烦恼","date":"2017-03-17T14:57:12.000Z","path":"2017/03/17/蓝桥杯-历届试题-国王的烦恼/","text":"问题描述 C国由n个小岛组成，为了方便小岛之间联络，C国在小岛间建立了m座大桥，每座大桥连接两座小岛。两个小岛间可能存在多座桥连接。然而，由于海水冲刷，有一些大桥面临着不能使用的危险。 如果两个小岛间的所有大桥都不能使用，则这两座小岛就不能直接到达了。然而，只要这两座小岛的居民能通过其他的桥或者其他的小岛互相到达，他们就会安然无事。但是，如果前一天两个小岛之间还有方法可以到达，后一天却不能到达了，居民们就会一起抗议。 现在C国的国王已经知道了每座桥能使用的天数，超过这个天数就不能使用了。现在他想知道居民们会有多少天进行抗议。输入格式 输入的第一行包含两个整数n, m，分别表示小岛的个数和桥的数量。 接下来m行，每行三个整数a, b, t，分别表示该座桥连接a号和b号两个小岛，能使用t天。小岛的编号从1开始递增。输出格式 输出一个整数，表示居民们会抗议的天数。样例输入4 41 2 21 3 22 3 13 4 3样例输出2样例说明 第一天后2和3之间的桥不能使用，不影响。 第二天后1和2之间，以及1和3之间的桥不能使用，居民们会抗议。 第三天后3和4之间的桥不能使用，居民们会抗议。数据规模和约定 对于30%的数据，1&lt;=n&lt;=20，1&lt;=m&lt;=100； 对于50%的数据，1&lt;=n&lt;=500，1&lt;=m&lt;=10000； 对于100%的数据，1&lt;=n&lt;=10000，1&lt;=m&lt;=100000，1&lt;=a, b&lt;=n， 1&lt;=t&lt;=100000。 思路： 使用并查集，按损坏时间倒序添加路径。 AC代码: #include &lt;iostream&gt; #include &lt;cstdio&gt; #include &lt;vector&gt; #include &lt;algorithm&gt; using namespace std; struct node{ int s; int e; int t; }b[100010]; bool cmp(node a,node b) { return a.t &gt; b.t; } int a[10001] = {0}; int find(int x) { int tx = x; int root; while(a[tx] != tx) { tx = a[tx]; } root = tx; while(a[x] != root) { tx = a[x]; a[x] = root; x = tx; } return root; } bool Union(int x,int y) { int tx = find(x); int ty = find(y); if(tx != ty) { a[tx] = ty; return true; } return false; } int n,m; int main() { cin &gt;&gt; n &gt;&gt; m; for(int i = 1; i &lt;= m; i++) { scanf(&quot;%d %d %d&quot;,&amp;b[i].s,&amp;b[i].e,&amp;b[i].t); } sort(b + 1, b + m + 1,cmp); for(int i = 1; i &lt;= n; i++) { a[i] = i; } int cnt = 0; int last = 0; for(int i = 1; i &lt;= m; i++) { if(Union(b[i].s,b[i].e) &amp;&amp; last != b[i].t) { last = b[i].t; cnt++; } } cout &lt;&lt; cnt; }","tags":[{"name":"题解","slug":"题解","permalink":"http://lossherl.github.io/tags/题解/"},{"name":"蓝桥杯","slug":"蓝桥杯","permalink":"http://lossherl.github.io/tags/蓝桥杯/"}]},{"title":"蓝桥杯 历届试题 最大子阵","date":"2017-03-17T14:52:47.000Z","path":"2017/03/17/蓝桥杯-历届试题-最大子阵/","text":"问题描述 给定一个n*m的矩阵A，求A中的一个非空子矩阵，使这个子矩阵中的元素和最大。 其中，A的子矩阵指在A中行和列均连续的一块。 输入格式 输入的第一行包含两个整数n, m，分别表示矩阵A的行数和列数。 接下来n行，每行m个整数，表示矩阵A。输出格式 输出一行，包含一个整数，表示A中最大的子矩阵中的元素和。样例输入3 3-1 -4 33 4 -1-5 -2 8样例输出10样例说明 取最后一列，和为10。数据规模和约定 对于50%的数据，1&lt;=n, m&lt;=50； 思路： 逐行递推，再逐列扫描最大值。 AC代码： #include &lt;iostream&gt; #include &lt;cmath&gt; #include &lt;cstdio&gt; #include &lt;cstring&gt; #include &lt;queue&gt; #include &lt;vector&gt; #include &lt;algorithm&gt; using namespace std; long long a[501][501] = {0}; long long dp[501][501] = {0}; long long b[501] = {0}; int main() { int n,m; long long ans = -999999; cin &gt;&gt; n &gt;&gt; m; for(int i = 1; i &lt;= n; i++) { for(int j = 1; j &lt;= m; j++) { cin &gt;&gt; a[i][j]; dp[i][j] = a[i][j] + dp[i][j - 1]; } } for(int i = 0; i &lt;= m; i++) { for(int j = i + 1; j &lt;= m; j++) { for(int k = 1; k &lt;= n; k++) { b[k] = dp[k][j] - dp[k][i]; } b[0] = 0; for(int k = 1; k &lt;= n; k++) { if(b[k - 1] &gt; 0) b[k] = b[k] + b[k - 1]; if(b[k] &gt; ans) ans = b[k]; } } } cout &lt;&lt; ans; }","tags":[{"name":"题解","slug":"题解","permalink":"http://lossherl.github.io/tags/题解/"},{"name":"蓝桥杯","slug":"蓝桥杯","permalink":"http://lossherl.github.io/tags/蓝桥杯/"}]},{"title":"LeetCode 141.Linked List Cycle","date":"2017-03-17T14:26:50.000Z","path":"2017/03/17/LeetCode-141-Linked-List-Cycle/","text":"Description: Given a linked list, determine if it has a cycle in it. Follow up:Can you solve it without using extra space? 使用双指针，一个每次走一步，另一个每次走两步，若存在环，指针将出现相等的情况。 代码: class Solution { public: bool hasCycle(ListNode *head) { ListNode *p1 = head; ListNode *p2 = head; while(p2 &amp;&amp; p2-&gt;next){ p1 = p1-&gt;next; p2 = p2-&gt;next-&gt;next; if(p1 == p2) return true; } return false; } };","tags":[{"name":"题解","slug":"题解","permalink":"http://lossherl.github.io/tags/题解/"},{"name":"LeetCode","slug":"LeetCode","permalink":"http://lossherl.github.io/tags/LeetCode/"}]},{"title":"LeetCode 221.Maximal square","date":"2017-03-17T14:17:50.000Z","path":"2017/03/17/LeetCode-221-Maximal-square/","text":"Description: Given a 2D binary matrix filled with 0’s and 1’s, find the largest square containing only 1’s and return its area. For example, given the following matrix: 1 0 1 0 01 0 1 1 11 1 1 1 11 0 0 1 0 Return 4. 动态规划可解 代码: class Solution { public: int maximalSquare(vector&lt;vector&lt;char&gt;&gt;&amp; matrix) { int n = matrix.size(); if(n == 0) return 0; int m = matrix[0].size(); if(m == 0) return 0; int ans = 0; vector&lt;vector&lt;int&gt;&gt; dp(n + 1); for(int i = 0; i &lt; dp.size(); i++) { dp[i].resize(m + 1); } for(int i = 1; i &lt;= n; i++) { for(int j = 1; j &lt;= m; j++) { if(matrix[i - 1][j - 1] == &apos;1&apos;) { dp[i][j] = min(min(dp[i-1][j],dp[i][j-1]),dp[i-1][j-1]) + 1; } ans = max(ans,dp[i][j]); } } return ans * ans; } };","tags":[{"name":"题解","slug":"题解","permalink":"http://lossherl.github.io/tags/题解/"},{"name":"LeetCode","slug":"LeetCode","permalink":"http://lossherl.github.io/tags/LeetCode/"}]},{"title":"CSP第九次认证 压缩编码","date":"2017-03-06T11:56:25.000Z","path":"2017/03/06/CSP第九次认证-压缩编码/","text":"问题描述 给定一段文字，已知单词a1, a2, …, an出现的频率分别t1, t2, …, tn。可以用01串给这些单词编码，即将每个单词与一个01串对应，使得任何一个单词的编码（对应的01串）不是另一个单词编码的前缀，这种编码称为前缀码。 使用前缀码编码一段文字是指将这段文字中的每个单词依次对应到其编码。一段文字经过前缀编码后的长度为： L=a1的编码长度×t1+a2的编码长度×t2+…+ an的编码长度×tn。 定义一个前缀编码为字典序编码，指对于1 ≤ i &lt; n，ai的编码（对应的01串）的字典序在ai+1编码之前，即a1, a2, …, an的编码是按字典序升序排列的。 例如，文字E A E C D E B C C E C B D B E中， 5个单词A、B、C、D、E出现的频率分别为1, 3, 4, 2, 5，则一种可行的编码方案是A:000, B:001, C:01, D:10, E:11，对应的编码后的01串为1100011011011001010111010011000111，对应的长度L为3×1+3×3+2×4+2×2+2×5=34。 在这个例子中，如果使用哈夫曼(Huffman)编码，对应的编码方案是A:000, B:01, C:10, D:001, E:11，虽然最终文字编码后的总长度只有33，但是这个编码不满足字典序编码的性质，比如C的编码的字典序不在D的编码之前。 在这个例子中，有些人可能会想的另一个字典序编码是A:000, B:001, C:010, D:011, E:1，编码后的文字长度为35。 请找出一个字典序编码，使得文字经过编码后的长度L最小。在输出时，你只需要输出最小的长度L，而不需要输出具体的方案。在上面的例子中，最小的长度L为34。输入格式 输入的第一行包含一个整数n，表示单词的数量。 第二行包含n个整数，用空格分隔，分别表示a1, a2, …, an出现的频率，即t1, t2, …, tn。请注意a1, a2, …, an具体是什么单词并不影响本题的解，所以没有输入a1, a2, …, an。输出格式 输出一个整数，表示文字经过编码后的长度L的最小值。样例输入 5 1 3 4 2 5样例输出 34 样例说明 这个样例就是问题描述中的例子。如果你得到了35，说明你算得有问题，请自行检查自己的算法而不要怀疑是样例输出写错了。评测用例规模与约定 对于30%的评测用例，1 ≤ n ≤ 10，1 ≤ ti ≤ 20； 对于60%的评测用例，1 ≤ n ≤ 100，1 ≤ ti ≤ 100； 对于100%的评测用例，1 ≤ n ≤ 1000，1 ≤ ti ≤ 10000。 动态规划，等同于石子归并问题。 代码： #include &lt;iostream&gt; #include &lt;cmath&gt; #include &lt;cstdio&gt; #include &lt;cstring&gt; #include &lt;string&gt; #include &lt;queue&gt; #include &lt;vector&gt; #include &lt;algorithm&gt; using namespace std; long long dp[1001][1001] = {0}; long long sum[1001] = {0}; int main() { int n; cin &gt;&gt; n; sum[0] = 0; for(int i = 1; i &lt;= n; i++) { cin &gt;&gt; sum[i]; sum[i] += sum[i - 1]; dp[i][i] = 0; } for(int len = 2; len &lt;= n; len++) { for(int i = 1; i &lt;= n - len + 1; i++) { int j = i + len - 1; long long mmin = 9999999999; int tsum = sum[j] - sum[i - 1]; for(int k = i; k &lt; j; k++) { mmin = min(mmin,dp[i][k] + dp[k + 1][j] + tsum); } dp[i][j] = mmin; } } cout &lt;&lt; dp[1][n] &lt;&lt; endl; return 0; }","tags":[{"name":"题解","slug":"题解","permalink":"http://lossherl.github.io/tags/题解/"},{"name":"CSP","slug":"CSP","permalink":"http://lossherl.github.io/tags/CSP/"}]}]